{"cells":[{"cell_type":"markdown","id":"e71ea7d4","metadata":{"id":"e71ea7d4"},"source":["--------------------------------------------------------------\n","# **HR Employee Attrition Prediction**\n","--------------------------------------------------------------"]},{"cell_type":"code","execution_count":null,"id":"yQdIqs8KTRaI","metadata":{"id":"yQdIqs8KTRaI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741058853372,"user_tz":-330,"elapsed":34418,"user":{"displayName":"Ankita Kapoor","userId":"00021354198552593218"}},"outputId":"b598e0fd-7515-40e1-8038-9c663e4f350d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","id":"ea1c25b1","metadata":{"id":"ea1c25b1"},"source":["---------------------\n","## **Context**\n","---------------------\n","\n","McCurr Healthcare Consultancy is an MNC that has thousands of employees spread out across the globe. The company believes in hiring the best talent available and retaining them for as long as possible. A huge amount of resources is spent on retaining existing employees through various initiatives. The Head of People Operations wants to bring down the cost of retaining employees. For this, he proposes limiting the incentives to only those employees who are at risk of attrition. As a recently hired Data Scientist in the People Operations Department, you have been asked to identify patterns in characteristics of employees who leave the organization. Also, you have to use this information to predict if an employee is at risk of attrition. This information will be used to target them with incentives.\n","\n","----------------------\n","## **Objective**  \n","----------------------\n","\n","* To identify the different factors that drive attrition\n","* To build a model to predict if an employee will attrite or not\n","\n","------------------------------------\n","## **Dataset Description**\n","------------------------------------\n","\n","The data contains information on employees' demographic details, work-related metrics, and attrition flag.\n","\n","* **EmployeeNumber** - Unique Employee Identifier\n","* **Attrition** - Did the employee attrite or not?\n","* **Age** - Age of the employee\n","* **BusinessTravel** - Travel commitments for the job\n","* **DailyRate** - Data description not available**\n","* **Department** - Employee's Department\n","* **DistanceFromHome** - Distance from work to home (in KM)\n","* **Education** - Employee's Education. 1-Below College, 2-College, 3-Bachelor, 4-Master, 5-Doctor\n","* **EducationField** - Field of Education\n","* **EnvironmentSatisfaction** - 1-Low, 2-Medium, 3-High, 4-Very High\n","* **Gender** - Employee's gender\n","* **HourlyRate** - Data description not available\n","* **JobInvolvement** - 1-Low, 2-Medium, 3-High, 4-Very High\n","* **JobLevel** - Level of job (1 to 5)\n","* **JobRole** - Job Roles\n","* **JobSatisfaction** - 1-Low, 2-Medium, 3-High, 4-Very High\n","* **MaritalStatus** - Marital Status\n","* **MonthlyIncome** - Monthly Salary\n","* **MonthlyRate** - Data description not available\n","* **NumCompaniesWorked** - Number of companies worked at\n","* **Over18** - Whether the employee is over 18 years of age?\n","* **OverTime** - Whether the employee is doing overtime?\n","* **PercentSalaryHike** - The percentage increase in the salary last year\n","* **PerformanceRating** - 1-Low, 2-Good, 3-Excellent, 4-Outstanding\n","* **RelationshipSatisfaction** - 1-Low, 2-Medium, 3-High, 4-Very High\n","* **StandardHours** - Standard Hours\n","* **StockOptionLevel** - Stock Option Level\n","* **TotalWorkingYears** - Total years worked\n","* **TrainingTimesLastYear** - Number of training attended last year\n","* **WorkLifeBalance** - 1-Low, 2-Good, 3-Excellent, 4-Outstanding\n","* **YearsAtCompany** - Years at Company\n","* **YearsInCurrentRole** - Years in the current role\n","* **YearsSinceLastPromotion** - Years since the last promotion\n","* **YearsWithCurrManager** - Years with the current manager\n","\n","**In the real world, you will not find definitions for some of your variables. It is the part of the analysis to figure out what they might mean**."]},{"cell_type":"markdown","id":"5373d723","metadata":{"id":"5373d723"},"source":["## **Importing the required libraries and overview of the dataset**"]},{"cell_type":"code","execution_count":null,"id":"292f10ad","metadata":{"id":"292f10ad"},"outputs":[],"source":["import pandas as pd\n","\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","\n","import seaborn as sns\n","\n","# To scale the data using z-score\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.model_selection import train_test_split\n","\n","# Algorithms to use\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","# Metrics to evaluate the model\n","from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n","\n","# For tuning the model\n","from sklearn.model_selection import GridSearchCV\n","\n","# To ignore warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"markdown","id":"myGCfEfyL4W-","metadata":{"id":"myGCfEfyL4W-"},"source":["### Note: The first section of the notebook is the section that has been covered in the previous case studies. For this discussion, this part can be skipped and we can directly refer to this **<a href = #link1>summary</a>** of data cleaning steps and observations from EDA.\n"]},{"cell_type":"markdown","id":"27c2e4a0","metadata":{"id":"27c2e4a0"},"source":["### **Loading the dataset**"]},{"cell_type":"code","execution_count":null,"id":"a7f654cf","metadata":{"id":"a7f654cf"},"outputs":[],"source":["# Reading the dataset\n","df = pd.read_excel('/content/drive/MyDrive/Predictive Analysis/HR_Employee_Attrition_Dataset.xlsx')"]},{"cell_type":"code","execution_count":null,"id":"8724dc93","metadata":{"id":"8724dc93","colab":{"base_uri":"https://localhost:8080/","height":325},"executionInfo":{"status":"ok","timestamp":1741058921372,"user_tz":-330,"elapsed":87,"user":{"displayName":"Ankita Kapoor","userId":"00021354198552593218"}},"outputId":"c606e5e5-a1cd-45bc-8761-f41943479113"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   EmployeeNumber Attrition  Age     BusinessTravel  DailyRate  \\\n","0               1       Yes   41      Travel_Rarely       1102   \n","1               2        No   49  Travel_Frequently        279   \n","2               3       Yes   37      Travel_Rarely       1373   \n","3               4        No   33  Travel_Frequently       1392   \n","4               5        No   27      Travel_Rarely        591   \n","\n","               Department  DistanceFromHome  Education EducationField  \\\n","0                   Sales                 1          2  Life Sciences   \n","1  Research & Development                 8          1  Life Sciences   \n","2  Research & Development                 2          2          Other   \n","3  Research & Development                 3          4  Life Sciences   \n","4  Research & Development                 2          1        Medical   \n","\n","   EnvironmentSatisfaction  ... RelationshipSatisfaction  StandardHours  \\\n","0                        2  ...                        1             80   \n","1                        3  ...                        4             80   \n","2                        4  ...                        2             80   \n","3                        4  ...                        3             80   \n","4                        1  ...                        4             80   \n","\n","   StockOptionLevel  TotalWorkingYears TrainingTimesLastYear  WorkLifeBalance  \\\n","0                 0                  8                     0                1   \n","1                 1                 10                     3                3   \n","2                 0                  7                     3                3   \n","3                 0                  8                     3                3   \n","4                 1                  6                     3                3   \n","\n","  YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n","0              6                   4                        0   \n","1             10                   7                        1   \n","2              0                   0                        0   \n","3              8                   7                        3   \n","4              2                   2                        2   \n","\n","   YearsWithCurrManager  \n","0                     5  \n","1                     7  \n","2                     0  \n","3                     0  \n","4                     2  \n","\n","[5 rows x 34 columns]"],"text/html":["\n","  <div id=\"df-6c8cf634-43d0-4991-8e77-89186b2041e4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EmployeeNumber</th>\n","      <th>Attrition</th>\n","      <th>Age</th>\n","      <th>BusinessTravel</th>\n","      <th>DailyRate</th>\n","      <th>Department</th>\n","      <th>DistanceFromHome</th>\n","      <th>Education</th>\n","      <th>EducationField</th>\n","      <th>EnvironmentSatisfaction</th>\n","      <th>...</th>\n","      <th>RelationshipSatisfaction</th>\n","      <th>StandardHours</th>\n","      <th>StockOptionLevel</th>\n","      <th>TotalWorkingYears</th>\n","      <th>TrainingTimesLastYear</th>\n","      <th>WorkLifeBalance</th>\n","      <th>YearsAtCompany</th>\n","      <th>YearsInCurrentRole</th>\n","      <th>YearsSinceLastPromotion</th>\n","      <th>YearsWithCurrManager</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Yes</td>\n","      <td>41</td>\n","      <td>Travel_Rarely</td>\n","      <td>1102</td>\n","      <td>Sales</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>Life Sciences</td>\n","      <td>2</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>No</td>\n","      <td>49</td>\n","      <td>Travel_Frequently</td>\n","      <td>279</td>\n","      <td>Research &amp; Development</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>Life Sciences</td>\n","      <td>3</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>10</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Yes</td>\n","      <td>37</td>\n","      <td>Travel_Rarely</td>\n","      <td>1373</td>\n","      <td>Research &amp; Development</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>Other</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>2</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>No</td>\n","      <td>33</td>\n","      <td>Travel_Frequently</td>\n","      <td>1392</td>\n","      <td>Research &amp; Development</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>Life Sciences</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>3</td>\n","      <td>80</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>No</td>\n","      <td>27</td>\n","      <td>Travel_Rarely</td>\n","      <td>591</td>\n","      <td>Research &amp; Development</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>Medical</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>4</td>\n","      <td>80</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 34 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c8cf634-43d0-4991-8e77-89186b2041e4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-6c8cf634-43d0-4991-8e77-89186b2041e4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-6c8cf634-43d0-4991-8e77-89186b2041e4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-ab705695-085c-4d84-befd-301ada01ca81\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab705695-085c-4d84-befd-301ada01ca81')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-ab705695-085c-4d84-befd-301ada01ca81 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":4}],"source":["df.head()"]},{"cell_type":"markdown","id":"9ca92deb","metadata":{"id":"9ca92deb"},"source":["### **Checking the info of the data**"]},{"cell_type":"code","execution_count":null,"id":"0054e419","metadata":{"id":"0054e419"},"outputs":[],"source":["df.info()"]},{"cell_type":"markdown","id":"30c0ba7c","metadata":{"id":"30c0ba7c"},"source":["**Observations:**\n","\n","- There are **2940 observations and 34 columns** in the data.\n","- All the column have 2940 non-null values, i.e., there are **no missing values** in the data."]},{"cell_type":"markdown","id":"0f711fa6","metadata":{"id":"0f711fa6"},"source":["**Let's check the number of unique values in each column.**"]},{"cell_type":"code","execution_count":null,"id":"51ca1a13","metadata":{"id":"51ca1a13"},"outputs":[],"source":["# Checking the number of unique values in each column\n","df.nunique()"]},{"cell_type":"markdown","id":"2f1391ea","metadata":{"id":"2f1391ea"},"source":["**Observations:**\n","\n","- Employee number is an identifier which is unique for each employee. We can drop this column as it would not add any value to our analysis.\n","- Over18 and StandardHours have only 1 unique value. We can drop these columns as they will not add any value to our analysis.\n","- On the basis of number of unique values in each column and the data description, we can identify the continuous and categorical columns in the data.\n","\n","Let's drop the columns mentioned above and define lists for numerical and categorical columns to explore them separately."]},{"cell_type":"code","execution_count":null,"id":"43913a63","metadata":{"id":"43913a63"},"outputs":[],"source":["# Dropping the columns\n","df = df.drop(['EmployeeNumber', 'Over18', 'StandardHours'], axis = 1)"]},{"cell_type":"code","execution_count":null,"id":"69cf1feb","metadata":{"id":"69cf1feb"},"outputs":[],"source":["# Creating numerical columns\n","num_cols = ['DailyRate', 'Age', 'DistanceFromHome', 'MonthlyIncome', 'MonthlyRate', 'PercentSalaryHike', 'TotalWorkingYears',\n","          'YearsAtCompany', 'NumCompaniesWorked', 'HourlyRate',\n","          'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'TrainingTimesLastYear']\n","\n","# Creating categorical variables\n","cat_cols = ['Attrition', 'OverTime', 'BusinessTravel', 'Department', 'Education', 'EducationField', 'JobSatisfaction',\n","            'EnvironmentSatisfaction', 'WorkLifeBalance', 'StockOptionLevel', 'Gender', 'PerformanceRating', 'JobInvolvement',\n","            'JobLevel', 'JobRole', 'MaritalStatus', 'RelationshipSatisfaction']"]},{"cell_type":"markdown","id":"449873dd","metadata":{"id":"449873dd"},"source":["## Exploratory Data Analysis"]},{"cell_type":"markdown","id":"85ec07be","metadata":{"id":"85ec07be"},"source":["### **Univariate analysis of numerical columns**"]},{"cell_type":"code","execution_count":null,"id":"47b95f91","metadata":{"id":"47b95f91"},"outputs":[],"source":["# Checking summary statistics\n","df[num_cols].describe().T"]},{"cell_type":"markdown","id":"504b9342","metadata":{"id":"504b9342"},"source":["**Observations:**\n","\n","- **Average employee age is around 37 years**. It has a high range, from 18 years to 60, indicating good age diversity in the organization.\n","- **At least 50% of the employees live within a 7 KM radius** of the organization. However, there are some extreme values, given that the maximum value is 29 km.\n","- **The average monthly income of an employee is USD 6500.** It has a high range of values from 1K-20K USD, which is to be expected for any organization's income distribution. There is a big difference between the 3rd quartile value (around USD 8400) and the maximum value (nearly USD 20000), showing that the **company's highest earners have a disproportionately large income** in comparison to the rest of the employees. Again, this is fairly common in most organizations.\n","- **The average salary hike of an employee is around 15%.** At least 50% of employees got a salary hike of 14% or less, with the maximum salary hike being 25%.\n","- The average number of years an employee is associated with the company is 7.\n","- **On average, the number of years since an employee got a promotion is ~2.19**. The majority of employees have been promoted since the last year."]},{"cell_type":"markdown","id":"59a45f42","metadata":{"id":"59a45f42"},"source":["Let's explore these variables in some more depth by observing their distributions."]},{"cell_type":"code","execution_count":null,"id":"eb0e50bf","metadata":{"id":"eb0e50bf"},"outputs":[],"source":["# Creating histograms\n","df[num_cols].hist(figsize = (14, 14))\n","\n","plt.show()"]},{"cell_type":"markdown","id":"e491f466","metadata":{"id":"e491f466"},"source":["**Observations:**\n","\n","- **The age distribution is close to a normal distribution**, with the majority of employees between the ages of 25 and 50.\n","- **DistanceFromHome also has a right-skewed distribution**, meaning most employees live close to work but there are a few that live further away.\n","- **MonthlyIncome and TotalWorkingYears are skewed to the right**, indicating that the majority of workers are in entry / mid-level positions in the organization.\n","- **The percentage salary hike is skewed to the right**, which means employees are mostly getting lower percentage salary increaseS.\n","- **The YearsAtCompany variable distribution shows a good proportion of workers with 10+ years**, indicating a significant number of loyal employees at the organization.\n","- **The YearsInCurrentRole distribution has three peaks at 0, 2, and 7.** There are a few employees that have even stayed in the same role for 15 years and more.\n","- **The YearsSinceLastPromotion variable distribution indicates that some employees have not received a promotion in 10-15 years and are still working in the organization.** These employees are assumed to be high work-experience employees in upper-management roles, such as co-founders, C-suite employees, etc.\n","- The distributions of DailyRate, HourlyRate, and MonthlyRate appear to be uniform and do not provide much information. It could be that the daily rate refers to the income earned per extra day worked while the hourly rate could refer to the same concept applied for extra hours worked per day. Since these rates tend to be broadly similar for multiple employees in the same department, that explains the uniform distribution they show."]},{"cell_type":"markdown","id":"e8fc6d32","metadata":{"id":"e8fc6d32"},"source":["### **Univariate analysis for categorical variables**"]},{"cell_type":"code","execution_count":null,"id":"52f52d39","metadata":{"id":"52f52d39"},"outputs":[],"source":["for i in cat_cols:\n","    print(df[i].value_counts(normalize = True))\n","\n","    print('*' * 40)"]},{"cell_type":"markdown","id":"4636bb12","metadata":{"id":"4636bb12"},"source":["**Observations:**\n","\n","- **The employee attrition rate is 16%.**\n","- **Around 28% of the employees are working overtime.** This number appears to be on the higher side and might indicate a stressed employee's work-life.\n","- 71% of the employees have traveled rarely, while around 19% have to travel frequently.\n","- Around 73% of the employees come from an educational background in the Life Sciences and Medical fields.\n","- Over 65% of employees work in the Research & Development department of the organization.\n","- **Nearly 40% of the employees have low (1) or medium (2) job satisfaction** and environment satisfaction in the organization, indicating that the morale of the company appears to be somewhat low.\n","- **Over 30% of the employees show low (1) to medium (2) job involvement.**\n","- Over 80% of the employees either have none or very less stock options.\n","- **In terms of performance ratings, none of the employees have been rated lower than 3 (excellent).** About 85% of employees have a performance rating equal to 3 (excellent), while the remaining have a rating of 4 (outstanding). This could either mean that the majority of employees are top performers, or the more likely scenario is that the organization could be highly lenient with its performance appraisal process."]},{"cell_type":"markdown","id":"74280d34","metadata":{"id":"74280d34"},"source":["### **Bivariate and Multivariate analysis**"]},{"cell_type":"markdown","id":"d6f0e060","metadata":{"id":"d6f0e060"},"source":["**We have analyzed different categorical and numerical variables. Let's now check how does attrition rate is related with other categorical variables**"]},{"cell_type":"code","execution_count":null,"id":"bddeec4e","metadata":{"id":"bddeec4e"},"outputs":[],"source":["for i in cat_cols:\n","    if i != 'Attrition':\n","        (pd.crosstab(df[i], df['Attrition'], normalize = 'index')*100).plot(kind = 'bar', figsize = (8, 4), stacked = True)\n","        plt.ylabel('Percentage Attrition %')"]},{"cell_type":"markdown","id":"3103a05c","metadata":{"id":"3103a05c"},"source":["**Observations:**\n","    \n","- **Employees working overtime have more than a 30% chance of attrition**, which is very high compared to the 10% chance of attrition for employees who do not work extra hours.\n","- As seen earlier, the majority of employees work for the R&D department. The chance of attrition there is ~15%\n","- **Employees working as sales representatives have an attrition rate of around 40%** while HRs and Technicians have an attrition rate of around 25%. The sales and HR departments have higher attrition rates in comparison to an academic department like Research & Development, an observation that makes intuitive sense keeping in mind the differences in those job profiles. The high-pressure and incentive-based nature of Sales and Marketing roles may be contributing to their higher attrition rates.\n","- **The lower the employee's job involvement, the higher their attrition chances appear to be, with 1-rated JobInvolvement employees attriting at 35%.** The reason for this could be that employees with lower job involvement might feel left out or less valued and have already started to explore new options, leading to a higher attrition rate.\n","- **Employees at a lower job level also attrite more,** with 1-rated JobLevel employees showing a nearly 25% chance of attrition. These may be young employees who tend to explore more options in the initial stages of their careers.\n","- **A low work-life balance rating leads employees to attrite**; ~30% of those in the 1-rated category show attrition."]},{"cell_type":"markdown","id":"8bf0c178","metadata":{"id":"8bf0c178"},"source":["**Let's check the relationship between attrition and Numerical variables**"]},{"cell_type":"code","execution_count":null,"id":"b41c07bf","metadata":{"id":"b41c07bf"},"outputs":[],"source":["# The mean of numerical variables grouped by attrition\n","df.groupby(['Attrition'])[num_cols].mean()"]},{"cell_type":"markdown","id":"163fcf00","metadata":{"id":"163fcf00"},"source":["**Observations:**\n","\n","- **Employees attriting the company have a nearly 30% lower average income and 30% lesser work experience than those who are not.** These could be the employees looking to explore new options and/or increase their salary with a company switch.\n","- **Employees showing attrition also tend to live 16% further from the office than those who are not**. The longer commute to and from work could mean they have to spend more time/money every day, and this could be leading to job dissatisfaction and wanting to leave the organization."]},{"cell_type":"markdown","id":"392f51dc","metadata":{"id":"392f51dc"},"source":["**We have found out what kind of employees are leaving the company more.**\n","\n","### **Let's check the relationship between different numerical variables**"]},{"cell_type":"code","execution_count":null,"id":"6b244527","metadata":{"id":"6b244527"},"outputs":[],"source":["# Plotting the correlation between numerical variables\n","plt.figure(figsize = (15, 8))\n","\n","sns.heatmap(df[num_cols].corr(), annot = True, fmt = '0.2f', cmap = 'YlGnBu')"]},{"cell_type":"markdown","id":"245278a6","metadata":{"id":"245278a6"},"source":["**Observations:**\n","\n","- **Total work experience, monthly income, years at the company, and years with the current managers are highly correlated with each other, and with employee age** which is easy to understand as these variables show an increase with age for most employees.\n","- Years at the company and years in the current role are correlated with years since the last promotion which means that the company is not giving promotions at the right time."]},{"cell_type":"markdown","id":"Mk0fKc9_L4XF","metadata":{"id":"Mk0fKc9_L4XF"},"source":["### <a id='link1'>Summary of EDA</a>\n","\n","**Data Description:**\n","\n","* There are **2940 observations and 34 columns** in the data.\n","* All the columns have 2940 non-null values, i.e., **there are no missing values** in the data.\n","* An **employee number is an identifier** that is unique for each employee. We can **drop this column** as it would not add any value to our analysis.\n","* **Over18 and StandardHours have only 1 unique value. We can drop these columns** as they will not add any value to our analysis.\n","* On the basis of the number of unique values in each column and the data description, we can **identify the continuous and categorical columns** in the data.\n","\n","**Data Cleaning:**\n","\n","* **The independent variables in this dataset have different scales**. When features have different scales from each other, there is a chance that a higher weightage will be given to features that have a higher magnitude, and they will dominate over other features whose magnitude changes may be smaller but whose percentage changes may be just as significant or even larger. **This will impact the performance of our machine learning algorithm**, and we do not want our algorithm to be biased towards one feature.\n","* The solution to this issue is **Feature Scaling**, i.e., scaling the dataset so as to give every transformed variable a comparable scale.\n","* In this problem, we will use the **Standard Scaler** method, which centers and scales the dataset using the Z-Score. It standardizes features by subtracting the mean and scaling it to have unit variance.\n","\n","\n","**Observations from EDA:**\n","\n","* The average employee age is around 37 years. It has a high range, from 18 years to 60, indicating good age diversity in the organization.\n","* At least 50% of the employees live within a 7 KM radius of the organization. However, there are some extreme values, given that the maximum value is 29 km.\n","* The average monthly income of an employee is USD 6500. It has a high range of values from 1K-20K USD, which is to be expected for any organization's income distribution. There is a big difference between the 3rd quartile value (around USD 8400) and the maximum value (nearly USD 20000), showing that the company's highest earners have a disproportionately large income in comparison to the rest of the employees. Again, this is fairly common in most organizations.\n","* The average salary hike of an employee is around 15%. At least 50% of employees got a salary hike of 14% or less, with the maximum salary hike being 25%.\n","* The average number of years an employee is associated with the company is 7.\n","* On average, the number of years since an employee got a promotion is ~2.19. The majority of employees have been promoted since the last year.\n","* The age distribution is close to a normal distribution, with the majority of employees between the ages of 25 and 50.\n","* DistanceFromHome also has a right-skewed distribution, meaning most employees live close to work but there are a few that live further away.\n","* MonthlyIncome and TotalWorkingYears are skewed to the right, indicating that the majority of workers are in entry / mid-level positions in the organization.\n","* The percentage salary hike is skewed to the right, which means employees are mostly getting lower percentage salary increases.\n","* The YearsAtCompany variable distribution shows a good proportion of workers with 10+ years, indicating a significant number of loyal employees at the organization.\n","* The YearsInCurrentRole distribution has three peaks at 0, 2, and 7. There are a few employees that have ever stayed in the same role for 15 years and more.\n","* The YearsSinceLastPromotion variable distribution indicates that some employees have not received a promotion in 10-15 years and are still working in the organization. These employees are assumed to be high work-experience employees in upper-management roles, such as co-founders, C-suite employees, etc.\n","* The distributions of DailyRate, HourlyRate, and MonthlyRate appear to be uniform and do not provide much information. It could be that the daily rate refers to the income earned per extra day worked while the hourly rate could refer to the same concept applied for extra hours worked per day. Since these rates tend to be broadly similar for multiple employees in the same department, that explains the uniform distribution they show.\n","* The employee attrition rate is 16%.\n","* Around 28% of the employees are working overtime. This number appears to be on the higher side and might indicate a stressed employee's work-life. Employees working overtime have more than a 30% chance of attrition, which is very high compared to the 10% chance of attrition for employees who do not work extra hours.\n","* 71% of the employees have traveled rarely, while around 19% have to travel frequently.\n","* Around 73% of the employees come from an educational background in the Life Sciences and Medical fields.\n","* Over 65% of employees work in the Research & Development department of the organization. The chance of attrition there is ~15%.\n","* Nearly 40% of the employees have low (1) or medium (2) job satisfaction and environment satisfaction in the organization, indicating that the morale of the company appears to be somewhat low.\n","* Over 30% of the employees show low (1) to medium (2) job involvement.\n","* Over 80% of the employees either have none or very less stock options.\n","* In terms of performance ratings, none of the employees have been rated lower than 3 (excellent). About 85% of employees have a performance rating equal to 3 (excellent), while the remaining have a rating of 4 (outstanding). This could either mean that the majority of employees are top performers, or the more likely scenario is that the organization could be highly lenient with its performance appraisal process.\n","* Employees working as sales representatives have an attrition rate of around 40% while HRs and Technicians have an attrition rate of around 25%. The sales and HR departments have higher attrition rates in comparison to an academic department like Research & Development, an observation that makes intuitive sense keeping in mind the differences in those job profiles. The high-pressure and incentive-based nature of Sales and Marketing roles may be contributing to their higher attrition rates.\n","* The lower the employee's job involvement, the higher their attrition chances appear to be, with 1-rated JobInvolvement employees attriting at 35%. The reason for this could be that employees with lower job involvement might feel left out or less valued and have already started to explore new options, leading to a higher attrition rate.\n","* Employees at a lower job level also attrite more, with 1-rated JobLevel employees showing a nearly 25% chance of attrition. These may be young employees who tend to explore more options in the initial stages of their careers.\n","* A low work-life balance rating leads employees to attrite; ~30% of those in the 1-rated category show attrition.\n","* Employees attriting the company have a nearly 30% lower average income and 30% lesser work experience than those who are not. These could be the employees looking to explore new options and/or increase their salary with a company switch.\n","* Employees showing attrition also tend to live 16% further from the office than those who are not. The longer commute to and from work could mean they have to spend more time/money every day, and this could be leading to job dissatisfaction and wanting to leave the organization.\n","* Total work experience, monthly income, years at the company, and years with the current managers are highly correlated with each other, and with employee age which is easy to understand as these variables show an increase with age for most employees.\n","* Years at the company and years in the current role are correlated with years since the last promotion which means that the company is not giving promotions at the right time."]},{"cell_type":"markdown","id":"GKopF7nwL4XG","metadata":{"id":"GKopF7nwL4XG"},"source":["**Now that we have explored our data, let's build the model**"]},{"cell_type":"markdown","id":"2c4cbc14","metadata":{"id":"2c4cbc14"},"source":["## **Model Building - Approach**\n","\n","1. Prepare the data for modeling.\n","2. Partition the data into train and test sets.\n","3. Build the model on the train data.\n","4. Tune the model if required.\n","5. Test the data on the test set."]},{"cell_type":"markdown","id":"5ec5695f","metadata":{"id":"5ec5695f"},"source":["###  **Preparing data for modeling**"]},{"cell_type":"markdown","id":"8ef8ca21","metadata":{"id":"8ef8ca21"},"source":["**Creating dummy variables for categorical Variables**"]},{"cell_type":"code","execution_count":null,"id":"8b2d6839","metadata":{"id":"8b2d6839"},"outputs":[],"source":["# Creating the list of columns for which we need to create the dummy variables\n","to_get_dummies_for = ['BusinessTravel', 'Department', 'Education', 'EducationField', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'MaritalStatus']\n","\n","# Creating dummy variables\n","df = pd.get_dummies(data = df, columns = to_get_dummies_for, drop_first = True)\n","\n","# Mapping overtime and attrition\n","dict_OverTime = {'Yes': 1, 'No': 0}\n","dict_attrition = {'Yes': 1, 'No': 0}\n","\n","df['OverTime'] = df.OverTime.map(dict_OverTime)\n","df['Attrition'] = df.Attrition.map(dict_attrition)"]},{"cell_type":"code","source":["print(df)"],"metadata":{"id":"ESemTl2YF_Mg"},"id":"ESemTl2YF_Mg","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"e131814b","metadata":{"id":"e131814b"},"source":["**Separating the independent variables (X) and the dependent variable (Y)**"]},{"cell_type":"code","execution_count":null,"id":"12e0b82d","metadata":{"id":"12e0b82d"},"outputs":[],"source":["# Separating the target variable and other variables\n","Y = df.Attrition\n","X = df.drop(columns = ['Attrition'])"]},{"cell_type":"markdown","id":"7394598d","metadata":{"id":"7394598d"},"source":["### **Scaling the data**\n","\n","The independent variables in this dataset have different scales. When features have different scales from each other, there is a chance that a higher weightage will be given to features that have a higher magnitude, and they will dominate over other features whose magnitude changes may be smaller but whose percentage changes may be just as significant or even larger. This will impact the performance of our machine learning algorithm, and we do not want our algorithm to be biased towards one feature.\n","\n","The solution to this issue is **Feature Scaling**, i.e. scaling the dataset so as to give every transformed variable a comparable scale.\n","\n","In this problem, we will use the **Standard Scaler** method, which centers and scales the dataset using the Z-Score.\n","\n","It standardizes features by subtracting the mean and scaling it to have unit variance.\n","\n","The standard score of sample x is calculated as:\n","\n","**z = (x - u) / s**\n","\n","where **u** is the mean of the training samples (zero) and **s** is the standard deviation of the training samples."]},{"cell_type":"code","execution_count":null,"id":"4f0eb320","metadata":{"id":"4f0eb320"},"outputs":[],"source":["# Scaling the data\n","sc = StandardScaler()\n","\n","X_scaled = sc.fit_transform(X)\n","\n","X_scaled = pd.DataFrame(X_scaled, columns = X.columns)"]},{"cell_type":"code","source":["print(X_scaled)"],"metadata":{"id":"sZYuCb98GivG"},"id":"sZYuCb98GivG","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"d3672252","metadata":{"id":"d3672252"},"source":["### **Splitting the data into 70% train and 30% test sets**"]},{"cell_type":"markdown","id":"5afcae64","metadata":{"id":"5afcae64"},"source":["Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance, there could be several times more negative samples than positive samples. In such cases, it is recommended to use the **stratified sampling** technique to ensure that relative class frequencies are approximately preserved in each train and validation fold."]},{"cell_type":"code","execution_count":null,"id":"d64830a1","metadata":{"id":"d64830a1"},"outputs":[],"source":["# Splitting the data\n","x_train, x_test, y_train, y_test = train_test_split(X_scaled, Y, test_size = 0.3, random_state = 1, stratify = Y)"]},{"cell_type":"markdown","id":"d6dbe209","metadata":{"id":"d6dbe209"},"source":["### **Model evaluation criterion**\n","\n","**The model can make two types of wrong predictions:**\n","\n","1. Predicting an employee will attrite when the employee doesn't attrite\n","2. Predicting an employee will not attrite when the employee actually attrites\n","\n","**Which case is more important?**\n","\n","* **Predicting that the employee will not attrite but the employee attrites**, i.e., losing out on a valuable employee or asset. This would be considered a major miss for any employee attrition predictor and is hence the more important case of wrong predictions.\n","\n","**How to reduce this loss i.e the need to reduce False Negatives?**\n","* **The company would want the Recall to be maximized**, the greater the Recall, the higher the chances of minimizing false negatives. Hence, the focus should be on increasing the Recall (minimizing the false negatives) or, in other words, identifying the true positives (i.e. Class 1) very well, so that the company can provide incentives to control the attrition rate especially, for top-performers. This would help in optimizing the overall project cost towards retaining the best talent."]},{"cell_type":"markdown","id":"bb8e8e39","metadata":{"id":"bb8e8e39"},"source":["Also, let's create a function to calculate and print the classification report and the confusion matrix so that we don't have to rewrite the same code repeatedly for each model."]},{"cell_type":"code","execution_count":null,"id":"003f79af","metadata":{"id":"003f79af"},"outputs":[],"source":["#Helper Function\n","\n","def metrics_score(actual, predicted):\n","\n","    print(classification_report(actual, predicted))\n","\n","    cm = confusion_matrix(actual, predicted)\n","\n","    plt.figure(figsize = (8, 5))\n","\n","    sns.heatmap(cm, annot = True, fmt = '.2f', xticklabels = ['Not Attrite', 'Attrite'], yticklabels = ['Not Attrite', 'Attrite'])\n","\n","    plt.ylabel('Actual')\n","\n","    plt.xlabel('Predicted')\n","\n","    plt.show()"]},{"cell_type":"markdown","id":"5670c9a2","metadata":{"id":"5670c9a2"},"source":["### **Building the model**\n","\n","We will be building 2 different models:\n","- **Logistic Regression**\n","- **K-Nearest Neighbors (K-NN)**"]},{"cell_type":"markdown","id":"GNVGgYh8L4XI","metadata":{"id":"GNVGgYh8L4XI"},"source":["### **Logistic Regression**"]},{"cell_type":"markdown","id":"ZJljeiMsL4XI","metadata":{"id":"ZJljeiMsL4XI"},"source":["- Logistic Regression is a supervised learning algorithm, generally used for **binary classification problems**, i.e., where the dependent variable is categorical and has only two possible values. In logistic regression, we use the sigmoid function to calculate the probability of an event Y, given some features X as:\n","\n","                                          P(Y)=1/(1 + exp(-X))"]},{"cell_type":"code","execution_count":null,"id":"dWMRJuT1L4XI","metadata":{"id":"dWMRJuT1L4XI"},"outputs":[],"source":["# Fitting the logistic regression model\n","lg = LogisticRegression()\n","\n","lg.fit(x_train,y_train)"]},{"cell_type":"markdown","id":"UufR004ML4XI","metadata":{"id":"UufR004ML4XI"},"source":["**Checking the model performance**"]},{"cell_type":"code","execution_count":null,"id":"l1ipU081L4XI","metadata":{"id":"l1ipU081L4XI"},"outputs":[],"source":["# Checking the performance on the training data\n","y_pred_train = lg.predict(x_train) #Default Probability 0.5\n","\n","metrics_score(y_train, y_pred_train)"]},{"cell_type":"code","execution_count":null,"id":"52EyPBLAZPUz","metadata":{"id":"52EyPBLAZPUz"},"outputs":[],"source":["lg.predict_proba(x_train)"]},{"cell_type":"code","execution_count":null,"id":"B76reh8DL4XJ","metadata":{"id":"B76reh8DL4XJ"},"outputs":[],"source":["# Checking the performance on the test dataset\n","y_pred_test = lg.predict(x_test)\n","metrics_score(y_test, y_pred_test)"]},{"cell_type":"markdown","id":"zOaqW6pYL4XJ","metadata":{"id":"zOaqW6pYL4XJ"},"source":["**Observations:**\n","- **We are getting an accuracy of about 90%** on the train and the test datasets.\n","- However, **the recall for this model is only around 50% for class 1 on the train data and 46% on the test data.**\n","- As the recall is low, **this model will not perform well** in differentiating out employees who have a high chance of attriting the company, meaning it will eventually not help in reducing the attrition rate.\n","- As we can see from the Confusion Matrix, **this model is not good at identifying employees who are at risk of attrition.**"]},{"cell_type":"markdown","id":"bo1kpJ-SL4XJ","metadata":{"id":"bo1kpJ-SL4XJ"},"source":["**Let's check the coefficients and find which variables are leading to attrition and which can help to reduce the attrition.**"]},{"cell_type":"code","execution_count":null,"id":"NaYJKaYWL4XJ","metadata":{"id":"NaYJKaYWL4XJ"},"outputs":[],"source":["# Printing the coefficients of logistic regression\n","cols = X.columns\n","\n","coef_lg = lg.coef_\n","\n","pd.DataFrame(coef_lg,columns = cols).T.sort_values(by = 0, ascending = False)"]},{"cell_type":"markdown","id":"4ycEzKnPL4XJ","metadata":{"id":"4ycEzKnPL4XJ"},"source":["**Observations:**\n","\n","\n","**Features which positively affect on the attrition rate are:**\n","- OverTime\n","- BusinessTravel_Travel_Frequently\n","- Department_Research & Development\n","- JobRole_Sales Executive\n","- MaritalStatus_Single\n","- Department_Sales\n","- NumCompaniesWorked\n","- YearsSinceLastPromotion\n","- JobLevel_5\n","- BusinessTravel_Travel_Rarely\n","- DistanceFromHome\n","- YearsAtCompany\n","- JobRole_Human Resources\n","- JobRole_Sales Representative\n","\n","**Features which negatively affect on the attrition rate are:**\n","- MonthlyIncome\n","- JobInvolvement_3\n","- JobLevel_2\n","- EnvironmentSatisfaction_4\n","- JobInvolvement_4\n","- JobInvolvement_2\n","- EnvironmentSatisfaction_3\n","- EducationField_Life Sciences\n","- EnvironmentSatisfaction_2\n","- YearsWithCurrManager\n","- JobRole_Research Director\n","- TotalWorkingYears\n","- JobSatisfaction\n","\n","**The coefficients that positively and negatively affect the attrition rate seem to be quite similar for logistic regression and LDA. This means they are capturing the same pattern and giving nearly the same conclusions from the dataset.**"]},{"cell_type":"markdown","id":"E45gU2WcL4XJ","metadata":{"id":"E45gU2WcL4XJ"},"source":["The coefficients of the logistic regression model give us the log of odds, which is hard to interpret in the real world. We can convert the log of odds into odds by taking its exponential."]},{"cell_type":"code","execution_count":null,"id":"cUDCPL3PL4XJ","metadata":{"id":"cUDCPL3PL4XJ"},"outputs":[],"source":["odds = np.exp(lg.coef_[0]) # Finding the odds\n","\n","# Adding the odds to a DataFrame and sorting the values\n","pd.DataFrame(odds, x_train.columns, columns = ['odds']).sort_values(by = 'odds', ascending = False)"]},{"cell_type":"markdown","id":"8b7658d0","metadata":{"id":"8b7658d0"},"source":["**Observations:**\n","\n","- The odds of an employee working overtime to attrite are **2.6 times** the odds of one who is not working overtime, probably because working overtime is not sustainable for an extended duration for any employee, and may lead to burnout and job dissatisfaction.\n","- The odds of an employee traveling frequently to attrite are **double** the odds of an employee who doesn't travel as often.\n","- The odds of single employees attriting are about **1.85 times (85% higher than)** the odds of an employee with another marital status."]},{"cell_type":"markdown","id":"LNg1vyERL4XK","metadata":{"id":"LNg1vyERL4XK"},"source":["**The Precision-Recall Curve for Logistic Regression**"]},{"cell_type":"code","execution_count":null,"id":"qWVDB_3aL4XK","metadata":{"id":"qWVDB_3aL4XK"},"outputs":[],"source":["y_scores_lg = lg.predict_proba(x_train) # predict_proba gives the probability of each observation belonging to each class\n","\n","\n","precisions_lg, recalls_lg, thresholds_lg = precision_recall_curve(y_train, y_scores_lg[:, 1])#Only for positive class\n","\n","# Plot values of precisions, recalls, and thresholds\n","plt.figure(figsize = (10, 7))\n","\n","plt.plot(thresholds_lg, precisions_lg[:-1], 'b--', label = 'precision')\n","\n","plt.plot(thresholds_lg, recalls_lg[:-1], 'g--', label = 'recall')\n","\n","plt.xlabel('Threshold')\n","\n","plt.legend(loc = 'upper left')\n","\n","plt.ylim([0, 1])\n","\n","plt.show()"]},{"cell_type":"markdown","id":"0prfei5ML4XK","metadata":{"id":"0prfei5ML4XK"},"source":["**Observation:**\n","- We can see that the precision and the recall are balanced for a threshold of about **0.35**.\n","\n","**Let's find out the performance of the model at this threshold.**"]},{"cell_type":"code","execution_count":null,"id":"0eOhXhV8L4XK","metadata":{"id":"0eOhXhV8L4XK"},"outputs":[],"source":["optimal_threshold1 = .35\n","\n","y_pred_train = lg.predict_proba(x_train)\n","\n","metrics_score(y_train, y_pred_train[:, 1] > optimal_threshold1)"]},{"cell_type":"markdown","id":"XAuSMJfxL4XK","metadata":{"id":"XAuSMJfxL4XK"},"source":["**Observations:**\n","\n","- **The model performance has improved. The recall has increased significantly for class 1.**\n","- Let's check the performance on the test data."]},{"cell_type":"code","execution_count":null,"id":"q5ZSv8ajL4XK","metadata":{"id":"q5ZSv8ajL4XK"},"outputs":[],"source":["optimal_threshold1 = .35\n","\n","y_pred_test = lg.predict_proba(x_test)\n","\n","metrics_score(y_test, y_pred_test[:, 1] > optimal_threshold1)"]},{"cell_type":"markdown","id":"DUqAZeCIL4XK","metadata":{"id":"DUqAZeCIL4XK"},"source":["**Observations:**\n","\n","- The model is giving a **similar performance on the test and the train datasets**, i.e., the model is giving a generalized performance.\n","- **The recall of the test data has increased** while at the same time, the precision has decreased slightly, which is to be expected while adjusting the threshold.\n","- The average recall and precision for the model are good but let's see if we can get even better performance using other algorithms."]},{"cell_type":"markdown","id":"sX5PvKiEL4XL","metadata":{"id":"sX5PvKiEL4XL"},"source":["### **K-Nearest Neighbors (K-NN)**"]},{"cell_type":"markdown","id":"1cc20d35","metadata":{"id":"1cc20d35"},"source":["K-NN uses features from the training data to predict the values of new data points, which means the new data point will be assigned a value based on how similar it is to the data points in the training set.\n","\n","\n","The following steps are performed in K-NN:\n","\n","- Select K\n","- Calculate distance (Euclidean, Manhattan, etc.)\n","- Find the K closest neighbors\n","- Take majority vote for labels\n","\n","The “K” in the K-NN algorithm is the number of nearest neighbors we wish to take the vote from. Generally, K is taken to be an odd number when the number of classes is even, so as to get a majority vote. Let's say K=3. In that case, we will make a circle with the new data point as the center just as big as enclosing only the three nearest data points on the plane.\n","\n","**But before actually building the model, we need to identify the value of K to be used in K-NN. We will perform the following steps for the same.**\n","\n","- For every value of K (from 1 to 15), split the training set into a new train and validation sets (30 times)\n","- Scale the training data and the validation data\n","- Take the average of the error on these training and the validation sets for each value of K\n","- Plot the average train vs validation error for all Ks\n","- Choose the optimal K from the plot where the two errors are comparable"]},{"cell_type":"code","execution_count":null,"id":"7a0de1a0","metadata":{"id":"7a0de1a0"},"outputs":[],"source":["knn = KNeighborsClassifier()\n","\n","# We select the optimal value of K for which the error rate is the least in the validation data\n","# Let us loop over a few values of K to determine the optimal value of K\n","\n","train_error = []\n","\n","test_error = []\n","\n","knn_many_split = {}\n","\n","error_df_knn = pd.DataFrame()\n","\n","features = X.columns\n","\n","for k in range(1, 15):\n","    train_error = []\n","\n","    test_error = []\n","\n","    lista = []\n","\n","    knn = KNeighborsClassifier(n_neighbors = k)\n","\n","    for i in range(30):\n","        x_train_new, x_val, y_train_new, y_val = train_test_split(x_train, y_train, test_size = 0.20)\n","\n","        # Fitting K-NN on the training data\n","        knn.fit(x_train_new, y_train_new)\n","\n","        # Calculating error on the training data and the validation data\n","        train_error.append(1 - knn.score(x_train_new, y_train_new))\n","\n","        test_error.append(1 - knn.score(x_val, y_val))\n","\n","    lista.append(sum(train_error)/len(train_error))\n","\n","    lista.append(sum(test_error)/len(test_error))\n","\n","    knn_many_split[k] = lista\n","\n","knn_many_split"]},{"cell_type":"code","execution_count":null,"id":"09df996c","metadata":{"id":"09df996c"},"outputs":[],"source":["kltest = []\n","\n","vltest = []\n","\n","for k, v in knn_many_split.items():\n","    kltest.append(k)\n","\n","    vltest.append(knn_many_split[k][1])\n","\n","kltrain = []\n","\n","vltrain = []\n","\n","for k, v in knn_many_split.items():\n","    kltrain.append(k)\n","\n","    vltrain.append(knn_many_split[k][0])\n","\n","# Plotting K vs Error\n","plt.figure(figsize = (10, 6))\n","\n","plt.plot(kltest, vltest, label = 'test' )\n","\n","plt.plot(kltrain, vltrain, label = 'train')\n","\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"markdown","id":"e37f9719","metadata":{"id":"e37f9719"},"source":["**Observations:**\n","- We can see that the test error (error on the validation data) is more or less similar for K greater than or equal to 5. But the training error keeps increasing with increasing K.\n","- This implies that we would get a lower train and test error if we choose K = 5. Also, if we choose a higher value of K, the model would get biased due to the imbalance in the dataset.\n","- So, let's fit the K-NN model with **K=5** on the entire training set."]},{"cell_type":"code","execution_count":null,"id":"b54689ec","metadata":{"id":"b54689ec"},"outputs":[],"source":["# Define K-NN model\n","\n","knn = KNeighborsClassifier(n_neighbors = 5)"]},{"cell_type":"code","execution_count":null,"id":"156441d1","metadata":{"id":"156441d1"},"outputs":[],"source":["# Fitting data to the K-NN model\n","\n","knn.fit(x_train,y_train)"]},{"cell_type":"code","execution_count":null,"id":"8be668f4","metadata":{"id":"8be668f4"},"outputs":[],"source":["# Checking the performance of K-NN model on the training data\n","y_pred_train_knn = knn.predict(x_train)\n","\n","metrics_score(y_train, y_pred_train_knn)"]},{"cell_type":"code","execution_count":null,"id":"96ae727c","metadata":{"id":"96ae727c"},"outputs":[],"source":["# Checking the performance of K-NN model on the testing data\n","y_pred_test_knn = knn.predict(x_test)\n","\n","metrics_score(y_test, y_pred_test_knn)"]},{"cell_type":"markdown","id":"d1dd7f23","metadata":{"id":"d1dd7f23"},"source":["**Observation:**\n","- The model gives a slightly better performance on the train in comparison to the test data but the **recall is not very good**. Let's see if we can improve on that."]},{"cell_type":"markdown","id":"985f476d","metadata":{"id":"985f476d"},"source":["**Let's try to fine tune this model and check if we could increase the Recall.**"]},{"cell_type":"markdown","id":"4420a7ab","metadata":{"id":"4420a7ab"},"source":["### **Using GridSearchCV for Hyperparameter tuning of the model**"]},{"cell_type":"markdown","id":"3b24adb6","metadata":{"id":"3b24adb6"},"source":["* Hyperparameter tuning is tricky in the sense that there is no direct way to calculate how a change in the hyperparameter value will reduce the loss of your model, so we usually resort to experimentation.\n","* **Grid search** is a model tuning technique that attempts to compute the optimum values of hyperparameters.\n","* It is an exhaustive search that is performed on specific parameter values of a model.\n","* The parameters of the estimator/model used to apply these methods are optimized by cross-validated grid-search over a parameter grid."]},{"cell_type":"markdown","id":"ff12491b","metadata":{"id":"ff12491b"},"source":["- **n_neighbors**\n","\n","    - Number of neighbors to use.\n","\n","\n","- **weights={'uniform', 'distance'}**\n","    - uniform : uniform weights. All points in each neighborhood are weighted equally.\n","    - distance : weight points by the inverse of their distance. In this case, the closest neighbors of a query point will have a greater influence than neighbors that are further away.\n","\n","\n","- **p**\n","    - When p = 1, this is equivalent to using Manhattan_distance (L1), and Euclidean_distance (L2) is used for p = 2."]},{"cell_type":"code","execution_count":null,"id":"41ca9c98","metadata":{"id":"41ca9c98"},"outputs":[],"source":["params_knn = {'n_neighbors': np.arange(3, 15), 'weights': ['uniform', 'distance'], 'p': [1, 2]}\n","\n","grid_knn = GridSearchCV(estimator = knn, param_grid = params_knn, scoring = 'recall', cv = 10)\n","\n","model_knn = grid_knn.fit(x_train,y_train)\n","\n","knn_estimator = model_knn.best_estimator_\n","\n","print(knn_estimator)"]},{"cell_type":"markdown","id":"b175b6d2","metadata":{"id":"b175b6d2"},"source":["- We have found the best hyperparameters for the K-NN classifier. Let's use these parameters to build the new K-NN model and find the recall of that model."]},{"cell_type":"code","execution_count":null,"id":"77ce4488","metadata":{"id":"77ce4488"},"outputs":[],"source":["# Fit the best estimator on the training data\n","knn_estimator.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"4ffc307d","metadata":{"id":"4ffc307d"},"outputs":[],"source":["y_pred_train_knn_estimator = knn_estimator.predict(x_train)\n","\n","metrics_score(y_train, y_pred_train_knn_estimator)"]},{"cell_type":"code","execution_count":null,"id":"f031d315","metadata":{"id":"f031d315"},"outputs":[],"source":["y_pred_test_knn_estimator = knn_estimator.predict(x_test)\n","\n","metrics_score(y_test, y_pred_test_knn_estimator)"]},{"cell_type":"markdown","id":"f45c698f","metadata":{"id":"f45c698f"},"source":["**Observations:**\n","\n","- This model seems to be overfitting but **the results have significantly improved** in comparison to previous models.\n","- **Test recall and precision have significantly increased** by tuning the K-NN classifier.\n","- This appears to be a high-performing model that the company can use to control the attrition rate. There is about an **83% chance** that the model will detect employees who are likely to leave the company, and the company can take the appropriate action."]},{"cell_type":"markdown","id":"4e39b499","metadata":{"id":"4e39b499"},"source":["## **Feature Importance using SHAP Library**"]},{"cell_type":"markdown","id":"498b657e","metadata":{"id":"498b657e"},"source":["With the aid of a visualization tool called SHAP, or **SHapley Additive exPlanations**, a machine learning model's output can be made more understandable. By calculating the contribution of each feature to the prediction, it can be used to explain the prediction by any model. The direction of the relationship (positive or negative) between the predictive variable and the target variable is also indicated by the SHAP values. A technique called SHAP values (SHapley Additive exPlanations), which is based on cooperative game theory, is **used to make machine learning models more transparent and understandable**.\n","\n","In a machine learning setting, a Shapley value is the contribution of a feature value to the difference between the actual prediction and the mean prediction."]},{"cell_type":"markdown","id":"8c0db9d2","metadata":{"id":"8c0db9d2"},"source":["### **Installing SHAP**\n","\n","To install the SHAP library, run the below command in a Jupyter notebook and restart the kernel.\n","\n","**!pip install shap**\n","\n","**Note:** You only need to install the library while running the code for the first time."]},{"cell_type":"code","execution_count":null,"id":"cafbad19","metadata":{"id":"cafbad19"},"outputs":[],"source":["!pip install shap"]},{"cell_type":"markdown","id":"f50d04c0","metadata":{"id":"f50d04c0"},"source":["### **SHAP Barplot**\n","\n","We plot the mean absolute value for each feature column as a bar chart if an **Explainer** with many samples is passed.\n","\n","We determine the **mean absolute SHAP** values across all observations for each feature. Since we do not want positive and negative numbers to cancel one another out, we take the absolute values. A mean SHAP plot will allow us to visualize the aggregated SHAP values.\n","\n","SHAP value helps us quantify feature's contribution towards a prediction. SHAP value closer to zero means the feature contributes little to the prediction whereas SHAP value away from zero indicates the feature contributes more. So, **large positive/negative SHAP values are found in features that significantly affect the model's predictions.**\n","\n","In the bar plot below, each feature is represented by a separate bar."]},{"cell_type":"code","execution_count":null,"id":"-UvxJqGwL4XN","metadata":{"id":"-UvxJqGwL4XN"},"outputs":[],"source":["# Importing the SHAP library\n","import shap as sh"]},{"cell_type":"code","execution_count":null,"id":"e5656c5c","metadata":{"id":"e5656c5c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fcf1372f-42dd-4a21-eb80-e8657ea879e1"},"outputs":[{"output_type":"stream","name":"stderr","text":["PermutationExplainer explainer:  48%|████▊     | 422/882 [24:42<26:02,  3.40s/it]"]}],"source":["# Fitting the Explainer\n","explainer = sh.Explainer(knn_estimator.predict, x_test)\n","\n","# Calculating the SHAP values. The below code might take some time to run.\n","shap_values = explainer(x_test)"]},{"cell_type":"code","execution_count":null,"id":"qQ5G-ZxCL4XO","metadata":{"id":"qQ5G-ZxCL4XO"},"outputs":[],"source":["sh.plots.bar(shap_values)"]},{"cell_type":"markdown","id":"12543682","metadata":{"id":"12543682"},"source":["**Note:** By default the bar plot only shows a maximum of ten bars, but this can be controlled with the **max_display parameter.**"]},{"cell_type":"code","execution_count":null,"id":"dae768d5","metadata":{"id":"dae768d5"},"outputs":[],"source":["sh.plots.bar(shap_values, max_display=15)"]},{"cell_type":"markdown","id":"aNMkwlhAi7Mo","metadata":{"id":"aNMkwlhAi7Mo"},"source":["**Observations:**\n","\n","- The above barplot from SHAP shows that **OverTime is the most important feature for the tuned K-NN model** to predict employee attrition because we can observe that overtime had the highest mean SHAP of all the features.\n","- Other 13 features displayed in the barplot, like EnvironmentSatisfication_4, MartialStatus_Single, WorkLifeBalance, etc., have the mean SHAP value of 0.01, which implies that these features are equally important for the model's predictions.\n","- The sum of the mean SHAP value for the rest of the 4o features is 0.3. It implies that there are some features with mean SHAP value of less than 0.01."]},{"cell_type":"markdown","id":"-pyEN1mqi78x","metadata":{"id":"-pyEN1mqi78x"},"source":["### **Summary Plot**\n","\n","The SHAP summary plot displays how each instance's (row of data) features contribute to the final prediction.\n","\n","- Here, the Y-axis indicates the variable name, in order of importance from top to bottom and the X-axis is the SHAP value, which indicates the impact on the model output.\n","- Each dot represents a row from the original dataset.\n","- The color of the data shows the features values. This allows us to see the how the SHAP values changes as the feature value changes. The color map on the right helps to understand which value is low and which value is high. If a feature has boolean values, it will take two colors, and for continuous features, it can contain the whole spectrum."]},{"cell_type":"code","execution_count":null,"id":"SQzQBqJXgd4H","metadata":{"id":"SQzQBqJXgd4H"},"outputs":[],"source":["sh.summary_plot(shap_values)"]},{"cell_type":"markdown","id":"BEBSHgFkX3_w","metadata":{"id":"BEBSHgFkX3_w"},"source":["**Observations:**\n","- The summary plot shows that **OverTime, MartialStatus_Single, and EnvironmentSatisfication_4** are the three most important features to predict whether an employee would attrite or not.\n","- We can observe that there is a positive impact on the model's output, indicated by positive SHAP value, as the value of OverTime increases, indicated by red colored dots. This implies that **employees having higher values of OverTime are more likely to attrite** (as Attrition=1 is the positive class).\n","- We can also observe that higher values of EnvironmentSatisfication_4, indicated by red dots, lead to a negative impact on the model's output. This implies that **employees having very high environment satisfaction (i.e. EnvironmentSatisfication_4=1) are less likely to attrite.**"]},{"cell_type":"markdown","id":"Imqsm6X1L4XO","metadata":{"id":"Imqsm6X1L4XO"},"source":["### **Force Plot**\n","\n","The SHAP force plot shows you exactly which feature had the most influence on the model's prediction for a **single observation.**\n","\n","The below graph explains a single prediction from the test set."]},{"cell_type":"code","execution_count":null,"id":"6dd9829d-ef30-45aa-bc90-855364364ca7","metadata":{"id":"6dd9829d-ef30-45aa-bc90-855364364ca7"},"outputs":[],"source":["explainer = sh.KernelExplainer(knn.predict_proba, x_train)\n","\n","shap_values1 = explainer.shap_values(x_test.iloc[0,:])\n","\n","sh.force_plot(explainer.expected_value[0], np.array([x[0] for x in shap_values1]), x_test.iloc[0,:], matplotlib = True, text_rotation=13, link='logit')"]},{"cell_type":"markdown","id":"zoVsnC-SnuFn","metadata":{"id":"zoVsnC-SnuFn"},"source":["**Observations:**\n","\n","- In the plot above, the **0.73** is the model's score for this observation. Here, the model's score can also be considered as the **probability of getting model output as 1**. The higher the probability, higher the chances of employee attrition.\n","- The **base value of ~0.70** is the predicted probability if there would have been no features. This is the reference value that the feature contributions start from.\n","- The features that were important to making the prediction for this observation are shown in red and blue, with **red representing features that pushed the predicted probability higher, and blue representing features that pushed the predicted probability lower**. Features that had more of an impact on the predicted probability are located closer to the dividing boundary between red and blue, and **the size of that impact is represented by the size of the bar**.\n","- Here, we observe that the majority of features are pushing the model's output towards a positive prediction where the feature **EducationField_Marketing** has the highest impact. The highest absolute SHAP value of EducationField_Marketing indicates that the employee being from the Marketing department was the most significant reason for the model predicting that this employee would attrite."]},{"cell_type":"markdown","id":"346e5aaf","metadata":{"id":"346e5aaf"},"source":["## **Conclusion and Recommendations**"]},{"cell_type":"markdown","id":"fd37c252","metadata":{"id":"fd37c252"},"source":["### **Conclusions:**\n","\n","- We have tried multiple models and were **able to identify the key factors involved with high attrition** in the organization.\n","- The final model, **a hyperparameter-tuned K-NN classifier**, is overfitting on the training dataset, but **gives the highest recall on the training and the testing datasets.** It may be possible to further try and tune the model, and the HR department can use this model to predict whether an employee is at risk of attrition or not."]},{"cell_type":"markdown","id":"548e59bb","metadata":{"id":"548e59bb"},"source":["### **Recommendations:**\n","\n","- We saw that **working overtime is the most important driver of attrition.** The organization should manage their work more efficiently so that employees don't have to work overtime and can manage to have a work-life balance, or failing this, the company could provide some additional incentives to employees who are working overtime to retain them.\n","- We observed that **approximately 40% of employees have given a poor rating on environment satisfaction**, possibly contributing to a higher attrition rate. The organization should focus on improving the culture and environment of the organization by coming up with new ideas to make the office environment more open and friendly.\n","- As observed, **the organization has higher attrition due to work-life balance.** The company might need to focus on giving flexible timings to employees instead making them work full-day. It can help the employees to feel less stressed and more productive in their work.\n","- **Frequent migration/traveling due to the job is also an important factor for attrition**. Employees traveling frequently for a greater distance due to office work are more likely to attrite. For such employees, the company could provide shuttle facilities so that the commute for such employees gets easier.\n","- The data and the model suggest that **lower job involvement leads to a higher likelihood of attrition**. This might be due to a lack of growth opportunities or a poor management style. A more proactive, hands-on approach may be required from the managers in the organization\n","- **A higher monthly income might lower the odds of an employee attriting.** The company should make sure that all its employees are compensated at least based on industry standards.\n","- **Young and relatively new/inexperienced employees tend to show a higher attrition rate, especially males.** The organization might be able to keep track of the problems that employees with less experience face in a better manner and come up with better ideas on how the management might help them. This may help create a healthier, more welcoming environment for younger male employees.\n","- The organization could come up with a revised CTC plan that includes stock options for a larger proportion of the employees to keep them motivated."]},{"cell_type":"markdown","id":"KQZQCgWaL4XP","metadata":{"id":"KQZQCgWaL4XP"},"source":["# **Optional Content**"]},{"cell_type":"markdown","id":"7m0H6ehKL4XP","metadata":{"id":"7m0H6ehKL4XP"},"source":["## **Building the model**\n","\n","We will be building 2 additional models:\n","- **Linear Discriminant Analysis (LDA)**\n","- **Quadratic Discriminant Analysis (QDA)**"]},{"cell_type":"markdown","id":"CrVIgmoLL4XP","metadata":{"id":"CrVIgmoLL4XP"},"source":["### **Linear Discriminant Analysis**"]},{"cell_type":"markdown","id":"u-xqIiwvL4XP","metadata":{"id":"u-xqIiwvL4XP"},"source":["Linear discriminant analysis (LDA) is generally used to classify patterns between two classes; however, it can be extended to classify multiple patterns. LDA assumes that all classes are linearly separable and according to this, multiple linear discrimination functions representing several hyperplanes in the feature space are created to distinguish between the classes. If there are two classes, then the LDA draws one hyperplane and projects the data onto this hyperplane in such a way as to maximize the separation of the two categories. This hyperplane is created according to two criteria considered simultaneously:\n","\n","- Maximizing the distance between the means of two classes.\n","- Minimizing the variation between each category."]},{"cell_type":"code","execution_count":null,"id":"RrJ7offyL4XP","metadata":{"id":"RrJ7offyL4XP"},"outputs":[],"source":["# Fitting the LDA model\n","lda = LinearDiscriminantAnalysis()\n","\n","lda.fit(x_train, y_train)"]},{"cell_type":"markdown","id":"93_p7RPkL4XP","metadata":{"id":"93_p7RPkL4XP"},"source":["**Checking Model Performance**"]},{"cell_type":"code","execution_count":null,"id":"Tosxi1hTL4XQ","metadata":{"id":"Tosxi1hTL4XQ"},"outputs":[],"source":["# Checking model performance of LDA\n","y_pred_train_lda = lda.predict(x_train)\n","\n","metrics_score(y_train, y_pred_train_lda)"]},{"cell_type":"markdown","id":"r_nK7eArL4XQ","metadata":{"id":"r_nK7eArL4XQ"},"source":["- The reported average includes the macro average which averages the unweighted mean per label, and the weighted average which averages the support-weighted mean per label.\n","- In classification, the class of interest is considered the positive class. Here, the class of interest is 1, i.e., identifying the employees at risk of attrition.\n","\n","**Reading the confusion matrix (clockwise from top left):**\n","\n","* True Negative (Actual = 0, Predicted = 0): Model predicts that an employee would not attrite and the employee does not attrite\n","\n","* False Positive (Actual = 0, Predicted = 1): Model predicts that an employee would attrite but the employee does not attrite\n","\n","* True Positive (Actual = 1, Predicted = 1): Model predicts that an employee would attrite and the employee actually attrites\n","\n","* False Negative (Actual = 1, Predicted = 0): Model predicts that an employee would not attrite but the employee attrites"]},{"cell_type":"markdown","id":"Wogk4xj3L4XQ","metadata":{"id":"Wogk4xj3L4XQ"},"source":["**Observations:**\n","\n","- The model is performing well in terms of accuracy.\n","- The recall for class 1 is quite low, which implies that this model will not perform well in differentiating the employees who have a high chance of leaving the company, and hence this model would not help reduce the attrition rate.\n","- The model is giving a decent average recall. A recall of ~0.75 suggests that there is a 25% (1 - 0.75) chance that the model will predict that a person is going to leave even though he/she would not, and the company would waste their time and energy on these employees who are not at risk of attrition."]},{"cell_type":"markdown","id":"lFyXcZEjL4XQ","metadata":{"id":"lFyXcZEjL4XQ"},"source":["We have built the LDA model. **Now, let's check the coefficients and find which variables are leading to attrition and which can help to reduce the attrition.**"]},{"cell_type":"code","execution_count":null,"id":"jSdYvUavL4XQ","metadata":{"id":"jSdYvUavL4XQ"},"outputs":[],"source":["# Creating the list of column names\n","cols = X.columns\n","\n","# Saving coefficients of LDA model\n","coef_lda = lda.coef_\n","\n","# Printing the cofficients of LDA\n","pd.DataFrame(coef_lda, columns = cols).T.sort_values(by = 0, ascending = False)"]},{"cell_type":"markdown","id":"CmbOZk7IL4XQ","metadata":{"id":"CmbOZk7IL4XQ"},"source":["**Some features which positively affect the Attrition rate are:**\n","- OverTime\n","- Department_Research & Development\n","- BusinessTravel_Travel_Frequently\n","- Department_Sales\n","- MaritalStatus_Single\n","- BusinessTravel_Travel_Rarely\n","- NumCompaniesWorked\n","- YearsSinceLastPromotion\n","- JobRole_Human Resources\n","- JobRole_Sales Executive\n","- YearsAtCompany\n","- DistanceFromHome\n","\n","**Some features which negatively affect the Attrition rate are:**\n","- JobInvolvement_3\n","- EducationField_Life Sciences\n","- JobInvolvement_2\n","- MonthlyIncome\n","- EducationField_Medical\n","- JobInvolvement_4\n","- JobLevel_2\n","- EnvironmentSatisfaction_4\n","- EnvironmentSatisfaction_3\n","- EnvironmentSatisfaction_2\n","- JobSatisfaction"]},{"cell_type":"markdown","id":"P9Y9N58YL4XR","metadata":{"id":"P9Y9N58YL4XR"},"source":["**Observations:**\n","\n","- Based on the LDA model, **Overtime is the most important feature** in detecting whether an employee would attrite or not.\n","- **This model also suggests that attrition is dependent on the employee's department.** Belonging to Sales or HR is shown to have a higher attrition rate, which is understood, but the model also seems to suggest that belonging to R&D contributes to a higher attrition rate, which is counter-intuitive. This could be because more than 65% of the employees are working in R&D, so the absolute number of employees who attrite from the company working in R&D will be significant even with a lower percentage. This is an example of Simpson's paradox and is evidence that a more powerful non-linear model may be necessary to accurately map the relationship between Department_Research & Development and the target variable.\n","- **Business traveling is an important variable in predicting the attrition rate.** Employees who either travel a lot or travel rarely have a higher attrition rate. This could be because those who travel often might feel overworked and dissatisfied with their role, whereas employees traveling rarely (in an organization where nearly 90% of all employees are traveling) could be a sign of them feeling undervalued and disinterested, and hence attriting more.\n","- **The number of companies the employee has worked for in the past also appears to impact the likelihood of attrition**. The greater the number, the higher the chance the employee will attrite. This suggests that employees who have worked for a higher number of companies may probably not stay loyal and may continue switching companies.\n","- Other features which appear to affect the chances of attrition are the number of years at the current company and the distance from home, both with positive correlations to attrition likelihood.\n","- The Job Involvement features being negatively correlated with attrition signify that **employees who are more involved in their jobs tend to attrite less.** This could probably be because a high degree of job involvement might make employees feel they are more important to the company, and hence discourage them from attrition.\n","- The model also captures the **inverse relationship between income and attrition** suggesting attrition rates can be controlled by increasing employee salary.\n","-  **Employees who are satisfied with the environment and the culture of the organization show a lower chance of attrition**, a conclusion that makes sense since a good work environment is likely to keep employees happy and prevent them from attriting.\n","- **Employees with higher total work experience and a good position in the organization are also less likely to attrite**, probably because working at the organization for several years and/or occupying a good position, tends to promote job stability and discourages volatility."]},{"cell_type":"markdown","id":"Zu3a6henL4XR","metadata":{"id":"Zu3a6henL4XR"},"source":["### **Precision-Recall Curve for LDA**\n","\n","**The Precision-Recall curve summarizes the trade-off between the precision and the recall for a predictive model using different probability thresholds.**"]},{"cell_type":"code","execution_count":null,"id":"UxWCn0l-L4XR","metadata":{"id":"UxWCn0l-L4XR"},"outputs":[],"source":["y_scores_lda = lda.predict_proba(x_train) # predict_proba gives the probability of each observation belonging to each class\n","\n","precisions_lda, recalls_lda, thresholds_lda = precision_recall_curve(y_train, y_scores_lda[:, 1])\n","\n","# Plot values of precisions, recalls, and thresholds\n","plt.figure(figsize = (10, 7))\n","\n","plt.plot(thresholds_lda, precisions_lda[:-1], 'b--', label = 'precision')\n","\n","plt.plot(thresholds_lda, recalls_lda[:-1], 'g--', label = 'recall')\n","\n","plt.xlabel('Threshold')\n","\n","plt.legend(loc = 'upper left')\n","\n","plt.ylim([0, 1])\n","\n","plt.show()"]},{"cell_type":"markdown","id":"R8NIUt3NL4XR","metadata":{"id":"R8NIUt3NL4XR"},"source":["**Observation:**\n","\n","- We can see that the precision and the recall are balanced for a threshold of about ~0.35."]},{"cell_type":"markdown","id":"P5bymIIfL4XR","metadata":{"id":"P5bymIIfL4XR"},"source":["**Let's check the model performance at this threshold**"]},{"cell_type":"code","execution_count":null,"id":"evr5q4loL4XS","metadata":{"id":"evr5q4loL4XS"},"outputs":[],"source":["optimal_threshold1 = .35\n","\n","y_pred_train_lda = lda.predict_proba(x_train)\n","\n","metrics_score(y_train, y_pred_train_lda[:,1] > optimal_threshold1)"]},{"cell_type":"markdown","id":"nEHDjvLQL4XS","metadata":{"id":"nEHDjvLQL4XS"},"source":["**Observations:**\n","\n","- The precision has dropped but **the recall for class 1 has increased to 0.60**; the class and metric of interest here.\n","- **The model is able to identify the majority of employees who are at risk of attrition,** and would hence be a more useful model than the previous iteration with the default threshold.\n","\n","Let's check the model performance on the test data"]},{"cell_type":"code","execution_count":null,"id":"ONTKzC3OL4XT","metadata":{"id":"ONTKzC3OL4XT"},"outputs":[],"source":["# Checking performance on the test data\n","optimal_threshold1 = .35\n","\n","y_pred_test_lda = lda.predict_proba(x_test)\n","\n","metrics_score(y_test, y_pred_test_lda[:,1] > optimal_threshold1)"]},{"cell_type":"markdown","id":"Fl3xIVZaL4XT","metadata":{"id":"Fl3xIVZaL4XT"},"source":["**Observations:**\n","\n","- The model is giving a **similar performance on the test and the train data**, meaning the model has generalized well.\n","- **The average recall and the precision for the model are good**, but let's see if we can get a better performance using other algorithms."]},{"cell_type":"markdown","id":"zzGbOlISL4XT","metadata":{"id":"zzGbOlISL4XT"},"source":["### **Quadratic Discriminant Analysis**"]},{"cell_type":"markdown","id":"HgepcWSqL4XT","metadata":{"id":"HgepcWSqL4XT"},"source":["Quadratic discriminant analysis (QDA) is a probabilistic parametric classification technique that represents an evolution of LDA for nonlinear class separations. QDA, like LDA, is based on the hypothesis that the probability density distributions are multivariate normal but, in this case, the dispersion is not the same for all of the categories."]},{"cell_type":"code","execution_count":null,"id":"oLepeiayL4XU","metadata":{"id":"oLepeiayL4XU"},"outputs":[],"source":["# Fitting QDA model\n","qda = QuadraticDiscriminantAnalysis()\n","\n","qda.fit(x_train, y_train)"]},{"cell_type":"code","execution_count":null,"id":"attrtUNvL4XU","metadata":{"id":"attrtUNvL4XU"},"outputs":[],"source":["# Checking model performance on the training data\n","y_pred_train_qda = qda.predict(x_train)\n","\n","metrics_score(y_train, y_pred_train_qda)"]},{"cell_type":"code","execution_count":null,"id":"Nodds6HgL4XV","metadata":{"id":"Nodds6HgL4XV"},"outputs":[],"source":["# Checking performance of the model on the test data\n","y_pred_test_qda = qda.predict(x_test)\n","\n","metrics_score(y_test, y_pred_test_qda)"]},{"cell_type":"markdown","id":"hA86kdf6L4XV","metadata":{"id":"hA86kdf6L4XV"},"source":["**Observations:**\n","\n","- QDA gives a very high recall for class 1, but the recall for class 0 is very poor which makes the **overall recall and accuracy of the model very low**.\n","- **The model has a high number of false positives**, i.e., the model will predict that the employee would attrite even though he/she would not.\n","- This is not a good model and will not be able to help the company with their objective."]}],"metadata":{"colab":{"provenance":[{"file_id":"13GplRR6gMzd92WqRMrqZezmtKJ4Aoe7R","timestamp":1741058560820}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}